{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2688a623-9cda-4592-8c9b-a8abf316c7a5",
    "_uuid": "517e144d-a983-424b-b514-783b62c8ce8a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:53:50.337072Z",
     "iopub.status.busy": "2025-09-17T11:53:50.336725Z",
     "iopub.status.idle": "2025-09-17T11:55:08.129301Z",
     "shell.execute_reply": "2025-09-17T11:55:08.128079Z",
     "shell.execute_reply.started": "2025-09-17T11:53:50.337041Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2ca5dcb-0209-4599-a56b-33f2446d6ed9",
    "_uuid": "e8ce7891-79ba-44a0-8d04-60b3ac3c124d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:55:08.132817Z",
     "iopub.status.busy": "2025-09-17T11:55:08.131844Z",
     "iopub.status.idle": "2025-09-17T11:55:24.871046Z",
     "shell.execute_reply": "2025-09-17T11:55:24.870315Z",
     "shell.execute_reply.started": "2025-09-17T11:55:08.132775Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run in a Kaggle cell. If Kaggle already has some packages, pip will skip/reinstall harmlessly.\n",
    "\n",
    "# NOTE: Tesseract + language packs may need system installs. Kaggle usually has tesseract installed.\n",
    "# If you have sudo on your environment (not usually on Kaggle), run:\n",
    "# sudo apt-get update && sudo apt-get install -y tesseract-ocr tesseract-ocr-hin tesseract-ocr-mar\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install pytesseract pillow python-docx python-pptx pdf2image pymupdf googletrans==4.0.0-rc1 sentence-transformers faiss-cpu transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a4cfbc7c-4f63-47eb-b727-ca8a065b8c7f",
    "_uuid": "6ef78482-8e49-4aa0-b9af-18a4d7303421",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:55:24.872535Z",
     "iopub.status.busy": "2025-09-17T11:55:24.872223Z",
     "iopub.status.idle": "2025-09-17T11:56:06.728226Z",
     "shell.execute_reply": "2025-09-17T11:56:06.727308Z",
     "shell.execute_reply.started": "2025-09-17T11:55:24.872507Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import tempfile\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# PDF and images\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Office docs\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "!pip install openpyxl xlrd\n",
    "\n",
    "# Translation\n",
    "from googletrans import Translator\n",
    "\n",
    "# Embeddings + FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Config - change these paths to your environment\n",
    "ROOT = Path(\"/kaggle/input/aaple-sarkar-db\")   # <-- keep your same data path here\n",
    "INDEX_DIR = Path(\"faiss_index\")                   # where index + metadata saved\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "TESSERACT_LANGS = \"eng+hin+mar\"  # English, Hindi, Marathi\n",
    "\n",
    "# Ensure index dir exists\n",
    "INDEX_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "translator = Translator()\n",
    "# Choose a sentence-transformer model (fast & good)\n",
    "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "emb_model = SentenceTransformer(EMB_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e764b5da-9fb1-40b7-8723-a6cb8ebeb5a5",
    "_uuid": "ab16e225-3cb3-4fbe-99c2-688dd1968408",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.729648Z",
     "iopub.status.busy": "2025-09-17T11:56:06.729388Z",
     "iopub.status.idle": "2025-09-17T11:56:06.735849Z",
     "shell.execute_reply": "2025-09-17T11:56:06.734944Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.729622Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    return \" \".join(s.split()).strip()\n",
    "\n",
    "def chunk_text(text: str, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP) -> List[str]:\n",
    "    text = clean_text(text)\n",
    "    if not text:\n",
    "        return []\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    L = len(text)\n",
    "    while start < L:\n",
    "        end = min(start + chunk_size, L)\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        if end == L:\n",
    "            break\n",
    "        start = end - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77a23154-3947-4561-b4e1-f560c9f98842",
    "_uuid": "941050ef-5af2-42b7-a614-1f0c1c88ed5d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.737989Z",
     "iopub.status.busy": "2025-09-17T11:56:06.737774Z",
     "iopub.status.idle": "2025-09-17T11:56:06.752724Z",
     "shell.execute_reply": "2025-09-17T11:56:06.752033Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.737973Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ocr_pil_image(img: Image.Image, langs: str = TESSERACT_LANGS) -> str:\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(img, lang=langs)\n",
    "    except Exception as e:\n",
    "        # fallback to default lang\n",
    "        text = pytesseract.image_to_string(img)\n",
    "    return clean_text(text)\n",
    "\n",
    "def ocr_image_file(path: Path) -> str:\n",
    "    img = Image.open(str(path))\n",
    "    return ocr_pil_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8fd3fde1-d585-4063-ae40-f9ad8fd16dda",
    "_uuid": "0673aaad-666a-4c9a-93c9-a6f771979d3c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.753648Z",
     "iopub.status.busy": "2025-09-17T11:56:06.753440Z",
     "iopub.status.idle": "2025-09-17T11:56:06.771167Z",
     "shell.execute_reply": "2025-09-17T11:56:06.770574Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.753631Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(path: Path) -> str:\n",
    "    doc = fitz.open(str(path))\n",
    "    page_texts = []\n",
    "    for i in range(len(doc)):\n",
    "        page = doc[i]\n",
    "        text = page.get_text(\"text\")\n",
    "        if text and text.strip():\n",
    "            page_texts.append(text)\n",
    "        else:\n",
    "            # scanned page -> render and OCR\n",
    "            pix = page.get_pixmap(dpi=200)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmp:\n",
    "                tmp.write(pix.tobytes(\"png\"))\n",
    "                tmp.flush()\n",
    "                tmp_path = Path(tmp.name)\n",
    "            try:\n",
    "                page_texts.append(ocr_image_file(tmp_path))\n",
    "            finally:\n",
    "                try:\n",
    "                    tmp_path.unlink()\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return clean_text(\"\\n\".join(page_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "166dde14-d7c2-47ca-b5c3-23ac67a9f189",
    "_uuid": "ec863461-e469-4cf9-8825-149d04d879a8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.772615Z",
     "iopub.status.busy": "2025-09-17T11:56:06.772059Z",
     "iopub.status.idle": "2025-09-17T11:56:06.785912Z",
     "shell.execute_reply": "2025-09-17T11:56:06.785130Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.772588Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "EXCEL_EXTS = {\".xlsx\", \".xls\"}\n",
    "\n",
    "def extract_text_from_excel(path: Path) -> str:\n",
    "    try:\n",
    "        # Read all sheets\n",
    "        xls = pd.ExcelFile(path)\n",
    "        all_texts = []\n",
    "        for sheet in xls.sheet_names:\n",
    "            df = pd.read_excel(xls, sheet_name=sheet, dtype=str)  # read as string\n",
    "            # Flatten the dataframe â†’ join as text\n",
    "            text = \"\\n\".join(\n",
    "                df.fillna(\"\").astype(str).apply(lambda row: \" | \".join(row), axis=1)\n",
    "            )\n",
    "            if text.strip():\n",
    "                all_texts.append(f\"[Sheet: {sheet}]\\n{text}\")\n",
    "        return clean_text(\"\\n\".join(all_texts))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Excel read failed {path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b69cfaae-d031-464a-a3d4-1fe792e7bc64",
    "_uuid": "a3cdf238-449d-4517-9616-adc79ab7b594",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.787064Z",
     "iopub.status.busy": "2025-09-17T11:56:06.786732Z",
     "iopub.status.idle": "2025-09-17T11:56:06.801355Z",
     "shell.execute_reply": "2025-09-17T11:56:06.800314Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.787035Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_text_from_docx(path: Path) -> str:\n",
    "    # Try normal text extraction first\n",
    "    try:\n",
    "        doc = Document(str(path))\n",
    "        paragraphs = [p.text for p in doc.paragraphs if p.text and p.text.strip()]\n",
    "        if paragraphs:\n",
    "            return clean_text(\"\\n\".join(paragraphs))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # fallback: extract images from docx zip and OCR them\n",
    "    texts = []\n",
    "    try:\n",
    "        with zipfile.ZipFile(str(path), 'r') as z:\n",
    "            media_files = [f for f in z.namelist() if f.startswith(\"word/media/\")]\n",
    "            for mf in media_files:\n",
    "                data = z.read(mf)\n",
    "                try:\n",
    "                    img = Image.open(io.BytesIO(data))\n",
    "                    texts.append(ocr_pil_image(img))\n",
    "                except Exception:\n",
    "                    continue\n",
    "    except Exception:\n",
    "        pass\n",
    "    return clean_text(\"\\n\".join(texts))\n",
    "\n",
    "def extract_text_from_pptx(path: Path) -> str:\n",
    "    try:\n",
    "        prs = Presentation(str(path))\n",
    "        slide_texts = []\n",
    "        slide_img_texts = []\n",
    "        for slide in prs.slides:\n",
    "            # textual shapes\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\") and shape.text and shape.text.strip():\n",
    "                    slide_texts.append(shape.text)\n",
    "            # image shapes: some shapes are pictures\n",
    "            for shape in slide.shapes:\n",
    "                try:\n",
    "                    if shape.shape_type == 13:  # picture\n",
    "                        img = shape.image\n",
    "                        data = img.blob\n",
    "                        pil = Image.open(io.BytesIO(data))\n",
    "                        slide_img_texts.append(ocr_pil_image(pil))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if slide_texts:\n",
    "            return clean_text(\"\\n\".join(slide_texts))\n",
    "        return clean_text(\"\\n\".join(slide_img_texts))\n",
    "    except Exception:\n",
    "        # final fallback: attempt to unzip media\n",
    "        texts = []\n",
    "        try:\n",
    "            with zipfile.ZipFile(str(path), 'r') as z:\n",
    "                media_files = [f for f in z.namelist() if f.startswith(\"ppt/media/\")]\n",
    "                for mf in media_files:\n",
    "                    data = z.read(mf)\n",
    "                    try:\n",
    "                        img = Image.open(io.BytesIO(data))\n",
    "                        texts.append(ocr_pil_image(img))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        return clean_text(\"\\n\".join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b52479a-dfa7-4df7-b38f-fc12d33614e9",
    "_uuid": "a7e7ebc8-b990-41a9-8d58-dd3baccd78f6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.802932Z",
     "iopub.status.busy": "2025-09-17T11:56:06.802189Z",
     "iopub.status.idle": "2025-09-17T11:56:06.821621Z",
     "shell.execute_reply": "2025-09-17T11:56:06.820884Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.802908Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_to_english(text: str) -> str:\n",
    "    text = clean_text(text)\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    try:\n",
    "        res = translator.translate(text, dest=\"en\")\n",
    "        return clean_text(res.text)\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "IMAGE_EXTS = {\".png\", \".jpg\", \".jpeg\", \".tiff\", \".bmp\", \".gif\"}\n",
    "DOC_EXTS = {\".pdf\", \".docx\", \".pptx\", \".txt\"} | EXCEL_EXTS\n",
    "\n",
    "def load_file_to_text(path: Path) -> str:\n",
    "    ext = path.suffix.lower()\n",
    "    extracted = \"\"\n",
    "    try:\n",
    "        if ext == \".pdf\":\n",
    "            extracted = extract_text_from_pdf(path)\n",
    "        elif ext in IMAGE_EXTS:\n",
    "            extracted = ocr_image_file(path)\n",
    "        elif ext == \".docx\":\n",
    "            extracted = extract_text_from_docx(path)\n",
    "        elif ext == \".pptx\":\n",
    "            extracted = extract_text_from_pptx(path)\n",
    "        elif ext in EXCEL_EXTS:\n",
    "            extracted = extract_text_from_excel(path)\n",
    "        elif ext == \".txt\":\n",
    "            extracted = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        else:\n",
    "            # fallback: try docx/pptx/image\n",
    "            try:\n",
    "                extracted = extract_text_from_docx(path)\n",
    "            except:\n",
    "                try:\n",
    "                    extracted = extract_text_from_pptx(path)\n",
    "                except:\n",
    "                    try:\n",
    "                        extracted = ocr_image_file(path)\n",
    "                    except:\n",
    "                        extracted = \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to extract {path}: {e}\")\n",
    "        extracted = \"\"\n",
    "\n",
    "    extracted = clean_text(extracted)\n",
    "    if not extracted:\n",
    "        return \"\"\n",
    "    return translate_to_english(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "81ac5212-eeb8-42ba-93f0-4683c74aff6d",
    "_uuid": "84b4421c-ad31-400d-8c82-2fe00e468cba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:06.822614Z",
     "iopub.status.busy": "2025-09-17T11:56:06.822390Z",
     "iopub.status.idle": "2025-09-17T11:56:08.024668Z",
     "shell.execute_reply": "2025-09-17T11:56:08.024002Z",
     "shell.execute_reply.started": "2025-09-17T11:56:06.822588Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save files\n",
    "INDEX_FILE = INDEX_DIR / \"index.faiss\"\n",
    "META_FILE = INDEX_DIR / \"meta.pkl\"\n",
    "\n",
    "def build_index(root: Path):\n",
    "    texts = []\n",
    "    metadata = []\n",
    "    print(\"Scanning files and extracting text (this may take time)...\")\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() not in DOC_EXTS and p.suffix.lower() not in IMAGE_EXTS:\n",
    "            continue\n",
    "        text = load_file_to_text(p)\n",
    "        if not text:\n",
    "            continue\n",
    "        chunks = chunk_text(text)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            texts.append(chunk)\n",
    "            metadata.append({\"source\": str(p), \"chunk_id\": i})\n",
    "\n",
    "    if not texts:\n",
    "        raise RuntimeError(\"No text found. Check ROOT path or extraction process.\")\n",
    "\n",
    "    print(f\"Encoding {len(texts)} chunks using {EMB_MODEL_NAME} ...\")\n",
    "    embeddings = emb_model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1e-10\n",
    "    embeddings = embeddings / norms\n",
    "\n",
    "    dim = embeddings.shape[1]\n",
    "    faiss_index = faiss.IndexFlatIP(dim)\n",
    "    faiss_index.add(embeddings.astype('float32'))\n",
    "\n",
    "    faiss.write_index(faiss_index, str(INDEX_FILE))\n",
    "    with open(META_FILE, \"wb\") as f:\n",
    "        pickle.dump({\"texts\": texts, \"metadata\": metadata}, f)\n",
    "    print(\"Index built and saved:\", INDEX_FILE, META_FILE)\n",
    "    return faiss_index, texts, metadata\n",
    "\n",
    "def load_index():\n",
    "    if not INDEX_FILE.exists() or not META_FILE.exists():\n",
    "        return None, None, None\n",
    "    faiss_index = faiss.read_index(str(INDEX_FILE))\n",
    "    with open(META_FILE, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return faiss_index, data[\"texts\"], data[\"metadata\"]\n",
    "\n",
    "# Build or load\n",
    "faiss_index, index_texts, index_metadata = load_index()\n",
    "if faiss_index is None:\n",
    "    faiss_index, index_texts, index_metadata = build_index(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85580e85-c768-4a65-a34f-a3021ffadb99",
    "_uuid": "264d3aed-2098-491d-a1b1-f7e8c6fc8fdf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:08.025621Z",
     "iopub.status.busy": "2025-09-17T11:56:08.025430Z",
     "iopub.status.idle": "2025-09-17T11:56:08.062733Z",
     "shell.execute_reply": "2025-09-17T11:56:08.061993Z",
     "shell.execute_reply.started": "2025-09-17T11:56:08.025606Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 4) -> List[Dict]:\n",
    "    q_emb = emb_model.encode([query], convert_to_numpy=True)\n",
    "    q_emb = q_emb / (np.linalg.norm(q_emb, axis=1, keepdims=True) + 1e-10)\n",
    "    q_emb = q_emb.astype('float32')\n",
    "    D, I = faiss_index.search(q_emb, k)  # âœ… use faiss_index\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        if idx < 0 or idx >= len(index_texts):\n",
    "            continue\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"text\": index_texts[idx],\n",
    "            \"metadata\": index_metadata[idx]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Example:\n",
    "q = \"What is country?\"\n",
    "res = retrieve(q, k=3)\n",
    "for r in res:\n",
    "    print(\"SCORE:\", r[\"score\"], \"SOURCE:\", r[\"metadata\"][\"source\"])\n",
    "    print(r[\"text\"][:400], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbd046a3-499e-44a6-aa1a-110dbbca2dff",
    "_uuid": "033a09f9-e9ed-4830-b658-d5717ee08a9a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:08.063785Z",
     "iopub.status.busy": "2025-09-17T11:56:08.063466Z",
     "iopub.status.idle": "2025-09-17T11:56:10.312870Z",
     "shell.execute_reply": "2025-09-17T11:56:10.311760Z",
     "shell.execute_reply.started": "2025-09-17T11:56:08.063767Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e6b51aa-58c0-40b8-b177-f8a182973ebb",
    "_uuid": "83cb15a3-3475-453b-b824-90967ba1699d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:10.314296Z",
     "iopub.status.busy": "2025-09-17T11:56:10.314022Z",
     "iopub.status.idle": "2025-09-17T11:56:12.614540Z",
     "shell.execute_reply": "2025-09-17T11:56:12.612825Z",
     "shell.execute_reply.started": "2025-09-17T11:56:10.314249Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dcca2226-c46e-42b6-ad1f-ace078588750",
    "_uuid": "78173cea-32d0-4bb3-b3de-565ad0c55ac9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:56:12.618122Z",
     "iopub.status.busy": "2025-09-17T11:56:12.617845Z",
     "iopub.status.idle": "2025-09-17T11:59:01.404642Z",
     "shell.execute_reply": "2025-09-17T11:59:01.404020Z",
     "shell.execute_reply.started": "2025-09-17T11:56:12.618096Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "\n",
    "# 1. Load Zephyr in 4-bit quantized mode (saves a LOT of memory)\n",
    "def init_zephyr_lowmem(model_name=\"HuggingFaceH4/zephyr-7b-alpha\"):\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quant_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "zephyr_pipe = init_zephyr_lowmem()\n",
    "\n",
    "# 2. Build prompt\n",
    "def assemble_context_and_prompt(query: str, retrieved: list) -> str:\n",
    "    context_parts = []\n",
    "    for i, r in enumerate(retrieved):\n",
    "        src = r[\"metadata\"].get(\"source\", \"unknown\")\n",
    "        snippet = r[\"text\"][:500]  # limit per chunk to avoid OOM\n",
    "        context_parts.append(f\"Source {i+1} ({src}):\\n{snippet}\")\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    return f\"\"\"You are Zephyr, a helpful assistant.\n",
    "Use the following context to answer the question as accurately as possible.\n",
    "If the answer is not present, say \"I don't know from the provided documents.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# 3. Call Zephyr\n",
    "def call_zephyr(prompt_text: str, max_new_tokens=256) -> str:\n",
    "    outputs = zephyr_pipe(\n",
    "        prompt_text,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        temperature=0\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt_text):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52c3be0d-caef-4036-9acb-9ea0b30169a4",
    "_uuid": "92a243dd-be37-43f2-b66f-8697ca6c15be",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:59:01.408163Z",
     "iopub.status.busy": "2025-09-17T11:59:01.407911Z",
     "iopub.status.idle": "2025-09-17T11:59:01.412892Z",
     "shell.execute_reply": "2025-09-17T11:59:01.412287Z",
     "shell.execute_reply.started": "2025-09-17T11:59:01.408143Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def answer_query(query: str, k: int = 4) -> str:\n",
    "    retrieved = retrieve(query, k=k)\n",
    "    prompt_text = assemble_context_and_prompt(query, retrieved)\n",
    "    return call_zephyr(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbfe2060-4465-4316-ad43-8fa9d316f35b",
    "_uuid": "bffbe217-2d6c-42fc-b14c-2a54f85e33ed",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:59:01.414191Z",
     "iopub.status.busy": "2025-09-17T11:59:01.413665Z",
     "iopub.status.idle": "2025-09-17T11:59:22.313219Z",
     "shell.execute_reply": "2025-09-17T11:59:22.312438Z",
     "shell.execute_reply.started": "2025-09-17T11:59:01.414166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"What is country?\"\n",
    "answer = answer_query(question, k=3)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0bd96ce1-ee99-4b25-b400-ab066fd86f3a",
    "_uuid": "6ab26264-5c83-46ce-8ddf-983b8cc6fe5e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T11:59:22.314469Z",
     "iopub.status.busy": "2025-09-17T11:59:22.314098Z",
     "iopub.status.idle": "2025-09-17T11:59:24.938248Z",
     "shell.execute_reply": "2025-09-17T11:59:24.937372Z",
     "shell.execute_reply.started": "2025-09-17T11:59:22.314443Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install flask flask-cors pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0567eecc-e83e-47be-b1ca-5e936f772585",
    "_uuid": "e118b87c-6895-4ed3-982e-b13db57fa357",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T12:01:32.925996Z",
     "iopub.status.busy": "2025-09-17T12:01:32.925353Z",
     "iopub.status.idle": "2025-09-17T12:01:32.949897Z",
     "shell.execute_reply": "2025-09-17T12:01:32.949270Z",
     "shell.execute_reply.started": "2025-09-17T12:01:32.925973Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# ðŸ”‘ paste your token here\n",
    "NGROK_AUTH_TOKEN = \"\"\n",
    "\n",
    "# set auth token\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4014d4f7-7ffc-4719-8373-89d062aa109e",
    "_uuid": "fe683eca-7845-4ec7-aaf4-0ebb615bc802",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-17T12:05:09.087136Z",
     "iopub.status.busy": "2025-09-17T12:05:09.086513Z",
     "iopub.status.idle": "2025-09-17T12:06:06.985044Z",
     "shell.execute_reply": "2025-09-17T12:06:06.984085Z",
     "shell.execute_reply.started": "2025-09-17T12:05:09.087110Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "from pyngrok import ngrok   # make sure you install with: pip install flask pyngrok\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Professional Chat UI\n",
    "chat_ui = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Zephyr Chatbot</title>\n",
    "    <style>\n",
    "        body {\n",
    "            margin: 0;\n",
    "            height: 100vh;\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            background: #f3f4f6;\n",
    "            font-family: 'Segoe UI', Tahoma, sans-serif;\n",
    "        }\n",
    "        .chat-wrapper {\n",
    "            width: 420px;\n",
    "            height: 600px;\n",
    "            background: white;\n",
    "            border-radius: 16px;\n",
    "            box-shadow: 0 8px 25px rgba(0,0,0,0.15);\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        .chat-header {\n",
    "            background: linear-gradient(135deg, #2563eb, #1e40af);\n",
    "            color: white;\n",
    "            padding: 14px 20px;\n",
    "            font-size: 18px;\n",
    "            font-weight: 600;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 10px;\n",
    "        }\n",
    "        .chat-header img {\n",
    "            width: 28px; height: 28px;\n",
    "        }\n",
    "        #chat-box {\n",
    "            flex: 1;\n",
    "            padding: 20px;\n",
    "            overflow-y: auto;\n",
    "            background: #f9fafb;\n",
    "        }\n",
    "        .message {\n",
    "            max-width: 75%;\n",
    "            padding: 12px 16px;\n",
    "            margin: 8px 0;\n",
    "            border-radius: 18px;\n",
    "            line-height: 1.4;\n",
    "            word-wrap: break-word;\n",
    "            animation: fadeIn 0.2s ease-in-out;\n",
    "        }\n",
    "        .user {\n",
    "            margin-left: auto;\n",
    "            background: #2563eb;\n",
    "            color: white;\n",
    "            border-bottom-right-radius: 4px;\n",
    "        }\n",
    "        .bot {\n",
    "            margin-right: auto;\n",
    "            background: #e5e7eb;\n",
    "            color: #111827;\n",
    "            border-bottom-left-radius: 4px;\n",
    "        }\n",
    "        .chat-input {\n",
    "            display: flex;\n",
    "            padding: 12px;\n",
    "            border-top: 1px solid #ddd;\n",
    "            background: white;\n",
    "        }\n",
    "        .chat-input input {\n",
    "            flex: 1;\n",
    "            border: none;\n",
    "            padding: 12px;\n",
    "            font-size: 15px;\n",
    "            border-radius: 25px;\n",
    "            outline: none;\n",
    "            background: #f3f4f6;\n",
    "        }\n",
    "        .chat-input button {\n",
    "            margin-left: 10px;\n",
    "            padding: 0 18px;\n",
    "            border: none;\n",
    "            border-radius: 25px;\n",
    "            background: #2563eb;\n",
    "            color: white;\n",
    "            font-weight: 500;\n",
    "            cursor: pointer;\n",
    "            transition: background 0.2s;\n",
    "        }\n",
    "        .chat-input button:hover {\n",
    "            background: #1e40af;\n",
    "        }\n",
    "        @keyframes fadeIn {\n",
    "            from {opacity: 0; transform: translateY(5px);}\n",
    "            to {opacity: 1; transform: translateY(0);}\n",
    "        }\n",
    "        .typing {\n",
    "            margin: 8px 0;\n",
    "            padding: 12px 16px;\n",
    "            border-radius: 18px;\n",
    "            background: #e5e7eb;\n",
    "            color: #6b7280;\n",
    "            font-style: italic;\n",
    "            font-size: 14px;\n",
    "            width: fit-content;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"chat-wrapper\">\n",
    "        <div class=\"chat-header\">\n",
    "            <img src=\"https://img.icons8.com/color/48/robot-2.png\"/>\n",
    "            Zephyr Chatbot\n",
    "        </div>\n",
    "        <div id=\"chat-box\"></div>\n",
    "        <div class=\"chat-input\">\n",
    "            <input id=\"user-input\" type=\"text\" placeholder=\"Type a message...\" onkeydown=\"if(event.key==='Enter') sendMessage()\" />\n",
    "            <button onclick=\"sendMessage()\">Send</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        async function sendMessage() {\n",
    "            let input = document.getElementById(\"user-input\");\n",
    "            let chatBox = document.getElementById(\"chat-box\");\n",
    "            let userMsg = input.value.trim();\n",
    "            if (!userMsg) return;\n",
    "\n",
    "            chatBox.innerHTML += \"<div class='message user'>\" + userMsg + \"</div>\";\n",
    "            input.value = \"\";\n",
    "            chatBox.scrollTop = chatBox.scrollHeight;\n",
    "\n",
    "            // Add typing indicator\n",
    "            let typingDiv = document.createElement(\"div\");\n",
    "            typingDiv.className = \"typing\";\n",
    "            typingDiv.innerText = \"Bot is typing...\";\n",
    "            chatBox.appendChild(typingDiv);\n",
    "            chatBox.scrollTop = chatBox.scrollHeight;\n",
    "\n",
    "            let response = await fetch(\"/ask\", {\n",
    "                method: \"POST\",\n",
    "                headers: { \"Content-Type\": \"application/json\" },\n",
    "                body: JSON.stringify({query: userMsg})\n",
    "            });\n",
    "\n",
    "            let data = await response.json();\n",
    "\n",
    "            // Remove typing indicator\n",
    "            chatBox.removeChild(typingDiv);\n",
    "\n",
    "            // Add bot response\n",
    "            chatBox.innerHTML += \"<div class='message bot'>\" + data.answer + \"</div>\";\n",
    "            chatBox.scrollTop = chatBox.scrollHeight;\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template_string(chat_ui)\n",
    "\n",
    "@app.route(\"/ask\", methods=[\"POST\"])\n",
    "def ask():\n",
    "    user_query = request.json.get(\"query\", \"\")\n",
    "    try:\n",
    "        answer = answer_query(user_query)  # âœ… your existing logic\n",
    "    except Exception as e:\n",
    "        answer = f\"Error: {str(e)}\"\n",
    "    return jsonify({\"answer\": answer})\n",
    "\n",
    "# Start ngrok tunnel + Flask\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"ðŸš€ Chatbot UI is live at:\", public_url)\n",
    "\n",
    "app.run(port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a99fff79-06b3-4e7f-a80b-1da02905a236",
    "_uuid": "1d538fe2-c614-4709-bc1a-bcf4cdd03c65",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8256059,
     "sourceId": 13038417,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8263529,
     "sourceId": 13049554,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8282452,
     "sourceId": 13077434,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8288527,
     "sourceId": 13086182,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
